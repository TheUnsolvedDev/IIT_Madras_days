import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import tqdm


from dataset import dataset
from algorithm import NaiveBayes
from algorithm import LogisticRegression
from algorithm import KNearestNeighbors
from algorithm import DecisionTree


def naive_bayes_training_and_testing():
    print('Model Type: NaiveBayes Classifier:')
    model = NaiveBayes()
    train_x, train_y, test_x, test_y = dataset('linear')
    model.fit(train_x, train_y)
    y_pred_train = model.predict(train_x)
    y_pred_test = model.predict(test_x)
    accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
    accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
    print('----------------------------------')
    print('Linear Classification Dataset:')
    print('Train Accuracy: ', accuracy_train)
    print('Test Accuracy: ', accuracy_test)
    train_x, train_y, test_x, test_y = dataset('nonlinear')
    model.fit(train_x, train_y)
    y_pred_train = model.predict(train_x)
    y_pred_test = model.predict(test_x)
    accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
    accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
    print('----------------------------------')
    print('Non-Linear Classification Dataset:')
    print('Train Accuracy: ', accuracy_train)
    print('Test Accuracy: ', accuracy_test)
    print('----------------------------------')
    print()

def logistic_regression_training_and_testing():
    print('Model Type: Logistic Regression:')
    model = LogisticRegression()
    
    train_x, train_y, test_x, test_y = dataset('linear')
    model.fit(train_x, train_y)
    y_pred_train = model.predict(train_x)
    y_pred_test = model.predict(test_x)
    accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
    accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
    
    print('----------------------------------')
    print('Linear Classification Dataset:')
    print('Train Accuracy: ', accuracy_train)
    print('Test Accuracy: ', accuracy_test)
    print('----------------------------------')
    
    print('Hyperparameter Tuning:')
    print('----------------------------------')
    print('Learning Rate:')
    learning_rate = [0.0001, 0.001, 0.01, 0.1, 1]
    train_accuracies,test_accuracies = [],[]
    for lr in tqdm.tqdm(learning_rate):
        model = LogisticRegression(lr=lr)
        model.fit(train_x, train_y)
        y_pred_train = model.predict(train_x)
        y_pred_test = model.predict(test_x)
        accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
        accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
        train_accuracies.append(accuracy_train)
        test_accuracies.append(accuracy_test)
    learning_rate = np.log10(learning_rate)
    plt.plot(learning_rate,train_accuracies, label='Train')
    plt.plot(learning_rate,test_accuracies, label='Test')
    plt.scatter(learning_rate,train_accuracies,label='Train')
    plt.scatter(learning_rate,test_accuracies,label='Test')
    plt.xlabel('Learning Rate 10^x')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Test'])
    plt.title('Learning Rate vs Accuracy')
    plt.savefig('lr_vs_accuracy_linear.png')
    plt.show()
    print('----------------------------------')
    
    train_x, train_y, test_x, test_y = dataset('nonlinear')
    model.fit(train_x, train_y)
    y_pred_train = model.predict(train_x)
    y_pred_test = model.predict(test_x)
    accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
    accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
    
    print('----------------------------------')
    print('Non-Linear Classification Dataset:')
    print('Train Accuracy: ', accuracy_train)
    print('Test Accuracy: ', accuracy_test)
    print('----------------------------------')
    
    print('Hyperparameter Tuning:')
    print('----------------------------------')
    print('Learning Rate:')
    learning_rate = [0.0001, 0.001, 0.01, 0.1, 1]
    train_accuracies,test_accuracies = [],[]
    for lr in tqdm.tqdm(learning_rate):
        model = LogisticRegression(lr=lr)
        model.fit(train_x, train_y)
        y_pred_train = model.predict(train_x)
        y_pred_test = model.predict(test_x)
        accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
        accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
        train_accuracies.append(accuracy_train)
        test_accuracies.append(accuracy_test)
    learning_rate = np.log10(learning_rate)
    
    plt.plot(learning_rate,train_accuracies, label='Train')
    plt.plot(learning_rate,test_accuracies, label='Test')
    plt.scatter(learning_rate,train_accuracies,label='Train')
    plt.scatter(learning_rate,test_accuracies,label='Test')
    plt.xlabel('Learning Rate 10^x')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Test'])
    plt.title('Learning Rate vs Accuracy')
    plt.savefig('lr_vs_accuracy_nonlinear.png')
    plt.show()
    print('----------------------------------')

def k_nearest_neighbors_training_and_testing():
    print('Model Type: K-Nearest Neighbors Classifier:')
    model = KNearestNeighbors(k=5)
    train_x, train_y, test_x, test_y = dataset('linear')
    model.fit(train_x, train_y)
    y_pred_train = model.predict(train_x)
    y_pred_test = model.predict(test_x)
    accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
    accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
    print('----------------------------------')
    print('Linear Classification Dataset:')
    print('Train Accuracy: ', accuracy_train)
    print('Test Accuracy: ', accuracy_test)
    print('----------------------------------')
    
    print('Hyperparameter Tuning:')
    print('----------------------------------')
    print('K:')
    k = [1, 3, 5, 7, 9]
    train_accuracies,test_accuracies = [],[]
    for i in tqdm.tqdm(k):
        model = KNearestNeighbors(k=i)
        model.fit(train_x, train_y)
        y_pred_train = model.predict(train_x)
        y_pred_test = model.predict(test_x)
        accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
        accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
        train_accuracies.append(accuracy_train)
        test_accuracies.append(accuracy_test)
    plt.plot(k,train_accuracies, label='Train')
    plt.plot(k,test_accuracies, label='Test')
    plt.scatter(k,train_accuracies,label='Train')
    plt.scatter(k,test_accuracies,label='Test')
    plt.xlabel('K')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Test'])
    plt.title('K vs Accuracy')
    plt.savefig('k_vs_accuracy_linear.png')
    plt.show()
    print('----------------------------------')
    
    model = KNearestNeighbors(k=5)
    train_x, train_y, test_x, test_y = dataset('nonlinear')
    model.fit(train_x, train_y)
    y_pred_train = model.predict(train_x)
    y_pred_test = model.predict(test_x)
    accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
    accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
    print('----------------------------------')
    print('Non-Linear Classification Dataset:')
    print('Train Accuracy: ', accuracy_train)
    print('Test Accuracy: ', accuracy_test)
    print('----------------------------------')
    
    print('Hyperparameter Tuning:')
    print('----------------------------------')
    print('K:')
    k = [1, 3, 5, 7, 9]
    train_accuracies,test_accuracies = [],[]
    for i in tqdm.tqdm(k):
        model = KNearestNeighbors(k=i)
        model.fit(train_x, train_y)
        y_pred_train = model.predict(train_x)
        y_pred_test = model.predict(test_x)
        accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
        accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
        train_accuracies.append(accuracy_train)
        test_accuracies.append(accuracy_test)
    plt.plot(k,train_accuracies, label='Train')
    plt.plot(k,test_accuracies, label='Test')
    plt.scatter(k,train_accuracies,label='Train')
    plt.scatter(k,test_accuracies,label='Test')
    plt.xlabel('K')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Test'])
    plt.title('K vs Accuracy')
    plt.savefig('k_vs_accuracy_nonlinear.png')
    plt.show()
    print()

def decision_tree_training_and_testing():
    print('Model Type: Decision Tree Classifier:')
    model = DecisionTree(max_depth=10)
    train_x, train_y, test_x, test_y = dataset('linear')
    model.fit(train_x, train_y)
    y_pred_train = model.predict(train_x)
    y_pred_test = model.predict(test_x)
    accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
    accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
    print('----------------------------------')
    print('Linear Classification Dataset:')
    print('Train Accuracy: ', accuracy_train)
    print('Test Accuracy: ', accuracy_test)
    print('----------------------------------')
    
    print('Hyperparameter Tuning:')
    print('----------------------------------')
    print('Max Depth:')
    max_depth = [1, 3, 5, 7, 9]
    train_accuracies,test_accuracies = [],[]
    for i in tqdm.tqdm(max_depth):
        model = DecisionTree(max_depth=i)
        model.fit(train_x, train_y)
        y_pred_train = model.predict(train_x)
        y_pred_test = model.predict(test_x)
        accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
        accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
        train_accuracies.append(accuracy_train)
        test_accuracies.append(accuracy_test)
    plt.plot(max_depth,train_accuracies, label='Train')
    plt.plot(max_depth,test_accuracies, label='Test')
    plt.scatter(max_depth,train_accuracies,label='Train')
    plt.scatter(max_depth,test_accuracies,label='Test')
    plt.xlabel('Max Depth')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Test'])
    plt.title('Max Depth vs Accuracy')
    plt.savefig('max_depth_vs_accuracy_linear.png')
    plt.show()
    print('----------------------------------')
    
    train_x, train_y, test_x, test_y = dataset('nonlinear')
    model.fit(train_x, train_y)
    y_pred_train = model.predict(train_x)
    y_pred_test = model.predict(test_x)
    accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
    accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
    print('----------------------------------')
    print('Non-Linear Classification Dataset:')
    print('Train Accuracy: ', accuracy_train)
    print('Test Accuracy: ', accuracy_test)
    print('----------------------------------')
    
    print('Hyperparameter Tuning:')
    print('----------------------------------')
    print('Max Depth:')
    max_depth = [1, 3, 5, 7, 9]
    train_accuracies,test_accuracies = [],[]
    for i in tqdm.tqdm(max_depth):
        model = DecisionTree(max_depth=i)
        model.fit(train_x, train_y)
        y_pred_train = model.predict(train_x)
        y_pred_test = model.predict(test_x)
        accuracy_train = np.sum(y_pred_train == train_y) / len(train_y)
        accuracy_test = np.sum(y_pred_test == test_y) / len(test_y)
        train_accuracies.append(accuracy_train)
        test_accuracies.append(accuracy_test)
    plt.plot(max_depth,train_accuracies, label='Train')
    plt.plot(max_depth,test_accuracies, label='Test')
    plt.scatter(max_depth,train_accuracies,label='Train')
    plt.scatter(max_depth,test_accuracies,label='Test')
    plt.xlabel('Max Depth')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Test'])
    plt.title('Max Depth vs Accuracy')
    plt.savefig('max_depth_vs_accuracy_nonlinear.png')
    plt.show()
    print('----------------------------------')
    print()

def main():
    # naive_bayes_training_and_testing()
    # logistic_regression_training_and_testing()
    # k_nearest_neighbors_training_and_testing()
    decision_tree_training_and_testing()

if __name__ == '__main__':
    main()
