{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfa99ea6-7383-4656-aac7-abb8862e389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import walk\n",
    "from nltk.corpus import stopwords\n",
    "from striprtf.striprtf import rtf_to_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea2162-3e3b-4772-ba78-ebd15c9ac627",
   "metadata": {},
   "source": [
    "# Training on a general online dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69f7599-ab0b-457b-8c02-acb1cbe1451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Label      5572 non-null   object\n",
      " 1   EmailText  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('spam.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f61199-dd54-4a1a-9cbc-a1c8a177cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['EmailText'].values\n",
    "y = data['Label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Converting String to Integer\n",
    "cv = CountVectorizer() \n",
    "X_train = cv.fit_transform(X_train)\n",
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff4a19ba-c652-473b-bcdd-1dae24eb51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9816363338252172\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc346e4-934e-40f2-8edb-e10c35da8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel = 'poly', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4532745-8c7c-4c5c-8dd8-611d8d219fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f90347-ecfb-492b-aa9d-36ae1e951c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel = 'sigmoid', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b6960-0dcf-47de-b64b-adfa9e74669c",
   "metadata": {},
   "source": [
    "# Training on Custom Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38497668-7244-4e87-b9f3-5ba827d56402",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathwalk = walk(\"enron-data/\")\n",
    "SpamData,HamData = [],[]\n",
    "\n",
    "for root,dr,files in pathwalk:\n",
    "    if \"spam\" in str(files):\n",
    "        for file in files:\n",
    "            with open(root + '/' + file,encoding='latin1') as ip:\n",
    "                SpamData.append(\" \".join(ip.readlines()))\n",
    "    if \"ham\" in str(files):\n",
    "        for file in files:\n",
    "            with open(root + '/' + file,encoding='latin1') as ip:\n",
    "                HamData.append(\" \".join(ip.readlines()))\n",
    "\n",
    "SpamData = list(set(SpamData))\n",
    "HamData = list(set(HamData))\n",
    "Data = SpamData + HamData\n",
    "Labels = [\"spam\"]*len(SpamData) + [\"ham\"]*len(HamData)\n",
    "\n",
    "raw_df = pd.DataFrame({\n",
    "    \"email\":Data,\n",
    "    \"label\":Labels\n",
    "})\n",
    "\n",
    "stopWords = stopwords.words('english')\n",
    "vectorizer = CountVectorizer(stop_words=stopWords)#,min_df=1)\n",
    "\n",
    "email = vectorizer.fit_transform(raw_df.email.to_list())\n",
    "label_encoder = sk.preprocessing.LabelEncoder()\n",
    "labels = label_encoder.fit_transform(raw_df.label)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(email,labels,train_size=0.8,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92f8d470-79ae-4628-954b-470ce439f5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9816363338252172\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd206ea8-2462-4694-9b88-9fbe42299a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6205935399245778\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'poly', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f70a1f2d-755c-461e-8823-8de55a04a908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9627807837350385\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1273e65-f12c-482e-a534-e7182ddcbcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9404820462370881\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'sigmoid', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a6856-56b2-42f1-80e1-133541ac614b",
   "metadata": {},
   "source": [
    "# Test Folder Reading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a475f1-b8c7-475e-9b8e-00c750716012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_emails():\n",
    "    testwalk = walk(\"test/\")\n",
    "    emails = []\n",
    "    for root,dr,files in testwalk:\n",
    "#         print(f\"{root},{dr},{files}\")\n",
    "        for file in files:\n",
    "            if \"email\"  in file:\n",
    "    #             print(file)\n",
    "                with open(root + file) as infile:\n",
    "                    content = infile.read()\n",
    "                    text = rtf_to_text(content)\n",
    "                emails.append(text)\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8a873-9c4e-4c64-a2b3-039814b11db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectorizer = CountVectorizer(stop_words=stopWords)#, min_df=1)\n",
    "\n",
    "X_test_ = test_vectorizer.fit_transform(read_test_emails()).toarray()\n",
    "X_test_mod = np.zeros((X_test_.shape[0],X_train.shape[1]))\n",
    "\n",
    "# print(vectorizer.vocabulary_)\n",
    "\n",
    "dict_train = vectorizer.vocabulary_\n",
    "dict_test = test_vectorizer.vocabulary_\n",
    "\n",
    "for key in dict_train.keys():\n",
    "    if key in dict_test.keys():\n",
    "#         print(f\"train:{dict_train[key]},test:{dict_test[key]}\")\n",
    "        X_test_mod[:,dict_train[key]] = X_test_[:,dict_test[key]]X_test_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8d130-b98c-4871-bbf9-1e74f0b0b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_mod)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
